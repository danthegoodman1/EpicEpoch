# EpicEpoch

An epic epoch service.

Generating monotonic timestamps at absurd concurrency, handles 1M concurrent requests or 1M req/s.

Used for distributed systems and clients, like distributed transactions. Self-sufficient via Raft.

<!-- TOC -->
* [EpicEpoch](#epicepoch)
  * [Reading the timestamp value](#reading-the-timestamp-value)
  * [HTTP endpoints (h1.1 & h2c)](#http-endpoints-h11--h2c)
  * [Client design](#client-design)
  * [Latency and concurrency](#latency-and-concurrency)
    * [Latency optimizations](#latency-optimizations)
    * [Concurrency optimizations](#concurrency-optimizations)
<!-- TOC -->

## Reading the timestamp value

The timestamp value is 16 bytes, constructed of an 8 byte timestamp (unix nanoseconds) + an 8 byte epoch index.

This ensures that transactions are always unique and in order, latency and concurrency for serving timestamp requests is maximized, and timestamps can be reversed for time-range queries against your data.

This also ensures that the request and response are each a single TCP frame.

## HTTP endpoints (h1.1 & h2c)

`/up` exists to check if the HTTP server is running
`/ready` checks to see if the node has joined the cluster and is ready to serve requests


`/timestamp` can be used to fetch the 16 byte timestamp value.


`/members` returns a JSON in the shape of:

```json
{
  "leader": {
    "nodeID": 1,
    "addr": "addr1"
  },
  "members": [
    {
      "nodeID": 1,
      "addr": "addr1"
    }
  ]
}
```

This is used for client-aware routing.

## Client design

See [CLIENT_DESIGN.md](CLIENT_DESIGN.md)

## Latency and concurrency

Optimizations have been made to reduce the latency and increase concurrency as much as possible, trading concurrency for latency where needed.

### Latency optimizations

Instead of using channels, ring buffers are used where ever practical (with some exceptions due to convenience). [Ring buffers are multiple times faster under high concurrency situations](https://bravenewgeek.com/so-you-wanna-go-fast/).

For example, all requests queue to have a timestamp generated by putting a request into a ring buffer. The reader agent is poked with a channel (for select convenience with shutdown), fetches the current epoch, reads from the ring buffer to generate timestamps, and responds to the request with a ring buffer provided in the request.

### Concurrency optimizations

The nature of the hybrid timestamp allows concurrency limited only by the epoch interval and a uint64. Within an epoch interval, a monotonic counter is incremented for every request, meaning that we are not bound to the write of raft to serve a request, and we can serve up to the max uint64 requests for a single epoch, which should be far faster than any server could serve pending requests. Ass a result the latency ceiling of request time is roughly the latency of a linearizable read through raft + the time to respond to all pending requests. The raft read is amortized across all pending requests.

The astute observer will recognize this as request collapsing!